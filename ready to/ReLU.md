ReLU함수는 활성화 함수 중 하나로 x값이 0보다 작을 때는 0으로 출력하고 0보다 클 때는 x값을 그대로 출력한다. 시그모이드 함수 사용시 나타날 수 있는 문제인 gradient vanishing을 해결할 수 있다. 
