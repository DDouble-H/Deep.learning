###### 경사하강학습법

- 지도 학습(supervised learning)
  
- 입력과 정답을 알려주고 정답을 맞추도록 하는 학습 방법
  
- 비지도 학습(unsupervised learning)
  
  - 정답없이 학습데이터로부터 유용한 정보를 추출하는 학습방법
  
- 학습매개변수(trainable parameters)
  
  - 학습과정에서 값이 변화하는 매개변수, 값의 변화에 따라 알고리즘 출력이 변화
  
- 손실함수(loss function)
  - 알고리즘이 얼마나 잘못하고 있는지를 표현하는 지표로서 손실함수의 값이 낮을수록 학습이 잘 된 것. 정답과 알고리즘 출력을 비교하는데에 사용됨
  - 어떤 손실함수를 사용하는지에 따라서 학습이 어떤 식으로 이루어지는지 결정, 정답의 형태가 결정됨
  - MSE, cross entropy error
  
- 최적화이론: 손실함수를 최소로하는 입력값을 찾아내는 것 (y의 min or max 값을 얻게하는 x값)

- 경사하강법(Gradient Descent)

  - 경사를 따라 여러번의 단계를 통해 최적점을 찾아내며 경사는 기울기(미분, gradient)를 이용해 계산

  - Learning rate
    - a에 비례해 이동함, a가 너무 작은 경우에 학습 속도가 느림, 적절한 학습률을 선택하는 것이 중요
  - 볼록함수(convex function) 
    - 볼록함수는 어디서 시작하더라도 경사하강법으로 최적값에 도달할 수 있음
  - 비볼록함수(non-convex fuction)
    - 시작위치에 따라 다른 최적값을 찾음 즉 지엽최적값(local minimum)에 빠질 위험이 있으며,  global minimum을 찾지 못할 수 있다.